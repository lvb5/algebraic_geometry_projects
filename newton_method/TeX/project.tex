\documentclass[11pt]{article}

\title{Exploring the Newton-Ralphson Method}
\author{Miles Cochran-Branson}
\date{Friday, November 5}
    
\include{project_code/preamble}
    
\begin{document}
    
\maketitle
    
\tableofcontents

\hypertarget{overview}{%
\section{Overview}\label{overview}}

We create a computational framework to implement Newton's method for
finding roots of polynomials. For the most basic, one variable, case
this looks like

\begin{equation}
x_{n + 1} = x_n - \frac{f(x_n)}{f'(x_n)}. 
\end{equation}

This algorithm finds the roots of a one-dimensional function. We want to
expand this method to solve \emph{systems} of equations. This is done by

\begin{equation}
\mathbf{x}_{n+1} = \mathbf{x_n} - J_F(\mathbf{x}_n)^{-1} F(\mathbf{x}_n)
\end{equation}

or, for sake of computation, we simply solve

\begin{equation}
J_F(\mathbf{x_n})(\mathbf{x}_{n+1} - \mathbf{x}_n) = -F(\mathbf{x}_n)
\end{equation}

for the quantity \(\mathbf{x}_{n+1} - \mathbf{x}_n\) so that we do not
have to compute the inverse of the Jacobian. We will write a function to
carry out the algorithm outlined above and will explore several examples
using the function we wrote. All computation will be done in
\texttt{Julia} with the packages found below

\input{project_code/code1}

    \hypertarget{solving-systems-of-equations-using-newton-method}{%
\section{Solving Systems of Equations Using Newton
Method}\label{solving-systems-of-equations-using-newton-method}}

We now create a function to solve a system of equations using the Newton
method and the same principles as above. That is, given a system of
equations we find a solution by using the recursive formula (3) and solve for \(\mathbf{x}_{n+1} - \mathbf{x}_n\). We then extract the value for \(\mathbf{x}_{n + 1}\) and repeat the process until a
particular tolerance is reached. This process is carried out in the
following function:

\input{project_code/code2}
    
\subsection{A first example}

    We then verify our solution by considering the case of minimizing the
function

\begin{equation}
    f : (x, y) \mapsto 2x^4 + y^4 + 2xy^2 - x^2 - \frac{1}{3}y^2 + 10. 
\end{equation}

In order to do this, we take the gradient of the above and then use
\texttt{newton\_solve} to find the minimum. We note that the gradient is
given by

\begin{equation}
    \nabla (x, y) = (8x^3 + 2y^2 - 2x, 4y^3 + 4xy - \frac{2}{3}y). 
\end{equation}

We start from the point $p = (2, 2)$ and commence the algorithm.

\input{project_code/code3}
        
    To show this is indeed a solution, we plug in our above solution and see
that we get zero.

\input{project_code/code4}

We then plot to visualize what our algorithm is doing. 
        
\input{project_code/code5}
    
and we see that everything works well. 

    \hypertarget{finding-the-closest-point-to-the-statistical-independence-model-using-newton-method}{%
\subsection{Finding the closest point to the statistical independence
model using Newton
Method}\label{finding-the-closest-point-to-the-statistical-independence-model-using-newton-method}}

We implement our above algorithm to minimize the distance to the statistical
independence model with defining equations

\begin{equation}
\begin{split}
x_1 + x_2 + x_3 + x_4 & = 1 \\
x_1 x_4 - x_2 x_3 = 0
\end{split}
\end{equation}

To find the closest points to the curve defined by these equations, we
minimize the distance formula using Lagrange multipliers, that is, we
solve the system of equations given by

\[
\begin{split}
x_1 + x_2 + x_3 + x_4 & = 1 \\
x_1 x_4 - x_2 x_3 & = 0 \\
2(x_1 - 1) & = \lambda_1 + \lambda_2 x_4 \\
2(x_2 - 5) & = \lambda_1 - \lambda_2 x_3 \\
2(x_3 - 2) & = \lambda_1 - \lambda_2 x_2 \\
2(x_4 - 3) & = \lambda_1 + \lambda_2 x_1
\end{split}
\]

where we have considered the distance to the point \(p = (1, 5, 2, 3) \in \mathbb{R}^4\). This
can be done easily using \texttt{newton\_solve} as follows

\input{project_code/code6}
        
    To verify this is a solution, we plug into the above system and find
that we get zero

\input{project_code/code7}

and we see that the point $p_{min} \approx (-1.6, 2.4, -0.37, 0.56)$ is the closest point on the surface to the point $p = (1,5,2,3)$. 

\break
        
    \hypertarget{finding-a-point-on-a-curve-using-newton-method}{%
\subsection{Finding a point on a curve using Newton
Method}\label{finding-a-point-on-a-curve-using-newton-method}}

We now find a point on the following curve using Newton

\[
(x, y) \mapsto (x^4 + y^4 - 1)(x^2 + y^2 - 2) + x^5y. 
\]

It turns out that simply starting from a point and applying
\texttt{newton\_solve} works in finding a point on the surface even in
the under-determined case. This is a result of the
\texttt{\textbackslash{}} operator automatically finding the norm of the
under-determined system created by taking the Jacobian of our function,
i.e.~\texttt{\textbackslash{}} automatically solves the system

\begin{equation}
Jx = f(p)
\end{equation}

for the minimum \(x\). This process is shown below

\input{project_code/code8}
        
    We then plot the steps taken by the algorithm and plot the surface to
visually see what our algorithm is doing.

\input{project_code/code9}
    
    Finally, we make sure our point lies on the curve by

\input{project_code/code10}
        
    \hypertarget{cases-of-non-convergence}{%
\subsection{Cases of non-convergence}\label{cases-of-non-convergence}}

Consider a system of equations that does \emph{not} converge such as

\begin{equation}
f : (x, y) \mapsto (x^2 + y^2 - 1, xy - 5)
\end{equation}

This can be visualized with the following plot:

 \input{project_code/code11}
    
    If we apply \texttt{newton\_solve} to this system this clearly throws an
error as shown below

\input{project_code/code12}

    Note that this error is something we wrote into our function when
convergence does not occur, i.e.~when the number of steps taken is
greater than 500. To fix this problem we could consider moving to the
complex numbers, however, \texttt{ForwardDiff} does not support complex
numbers, thus we would need to use a different function to find the
gradient.

For a visualization of what's going on, we plot the first ten points
computed by \texttt{newton\_solve} and display them below.

\input{project_code/code13}
\input{project_code/code14}
    
    From this we can clearly see that the algorithm will not converge and
will rather eventually step off into infinity.

\section{Conclusions}

The above examples illustrate how we can use the Newton-Ralphson method
to find solutions to systems of multivariate equations. This method
clearly has flaws. Consider our first example in section 1.1. We can see
from the picture created that there should be a total of \emph{six}
solutions. We could find all of these by changing our starting point,
but this becomes tedious and, for higher dimensional objects, may not be
possible. Clearly a better method is needed in finding solutions, or our
algorithm must be improved.

Despite these obvious problems, Newton's method is incredibly fast and
the algorithm, when convergence is possible, converges very quickly.
Other methods that are more powerful, such as
\texttt{Homotopy\ Continuation}, can take a very long time to run. Thus,
we conclude that while Newton is a very powerful tool, other methods are
needed to more fully explore systems of equations.
    
    
\end{document}
